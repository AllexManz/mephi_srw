# LoRA configuration for GPT-2
peft:
  method: lora
  enabled: true
  adapter_path: null
  common:
    task_type: CAUSAL_LM
    inference_mode: false
  lora:
    r: 8
    alpha: 16
    target_modules: ["c_attn", "c_proj"]  # GPT-2 specific modules
    lora_dropout: 0.1
    bias: none
    modules_to_save: null 