# Training Configuration
output_dir: "models/security_llm"  # Директория для сохранения модели
max_length: 512  # Максимальная длина последовательности
num_epochs: 3  # Количество эпох обучения
batch_size: 8  # Размер батча
learning_rate: 1e-5  # Скорость обучения
warmup_steps: 100  # Количество шагов для разогрева
weight_decay: 0.01  # Вес регуляризации
logging_steps: 100  # Частота логирования
eval_steps: 500  # Частота оценки
save_steps: 1000  # Частота сохранения
fp16: true  # Использовать mixed precision training
gradient_accumulation_steps: 4  # Количество шагов для накопления градиентов 